{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52ca91fe",
   "metadata": {},
   "source": [
    "### Importamos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89ae0fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323302d4",
   "metadata": {},
   "source": [
    "### Variables de entorno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d85b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a057ecce",
   "metadata": {},
   "source": [
    "### Subimos el documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6721387",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def upload_pdf(url: str):        \n",
    "    try:\n",
    "        loader = PyPDFLoader(url)\n",
    "        loader = loader.lazy_load()\n",
    "\n",
    "        text = \"\"\n",
    "\n",
    "        for page in loader: \n",
    "            text += page.page_content + \"\\n\"\n",
    "\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197416b6",
   "metadata": {},
   "source": [
    "## Text Splitter para separar todo el contenido de mi documento\n",
    "### aumento del chunk size para la obtenci√≥n de oraciones m√°s largas\n",
    "### Decremento del chunk_overlap para intentar hacerle perder el contexto al modelo, diviendo las frases importantes para que pierda la relaci√≥n entre las palabras\n",
    "\n",
    "- CharacterTextSplitter es m√°s directo, divide el texto en trozos peque√±os fijos.\n",
    "- Aqu√≠ utilic√© RecursiveCharacterTextSplitter que seg√∫n la documentaci√≥n es m√°s inteligente y jerarquico, ideal para PDFs, libros o documentaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db664495",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_splitter(text): \n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap = 30\n",
    "    )\n",
    "    texts = text_splitter.create_documents([text])\n",
    "    print(texts)\n",
    "    return texts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf35666",
   "metadata": {},
   "source": [
    "# Defino el modelo que utilizar√©\n",
    "\n",
    "1. Nuevo modelo de embedding de ollama (mxbai-embed-large): Es un modelo de incrustaci√≥n (embedding) de lenguaje de √∫ltima generaci√≥n, de c√≥digo abierto, desarrollado por Mixedbread.ai. \n",
    "- Su funci√≥n principal es transformar texto (palabras, frases o documentos) en representaciones num√©ricas de alta dimensi√≥n, conocidas como vectores. Estos vectores capturan el significado sem√°ntico y sint√°ctico del texto, lo que permite a los sistemas de IA comprender la relaci√≥n y similitud entre diferentes fragmentos de texto. \n",
    "\n",
    "* Este modelo solicit√≥ otra vector Store ya que el anterior tenia un soporte para 768 dimensiones y este tiene hasta 1024 dimensiones al tratarse de un modelo de embedding m√°s grande. Entonces, ¬øa qu√© me refiero con dimensiones? la cantidad de n√∫meros con los que cuenta un vector creado por el embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90bc142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OllamaEmbeddings(\n",
    "    model = \"mxbai-embed-large:latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193725a0",
   "metadata": {},
   "source": [
    "### Creo mi base de datos vectorial donde se guardar√° mi embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db426117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_store(name_collection: str): \n",
    "    \n",
    "    vector_store = Chroma(\n",
    "    collection_name= name_collection,\n",
    "    embedding_function=embedding,\n",
    "    persist_directory=\"./prueba_chroma\"\n",
    ")    \n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7da8de",
   "metadata": {},
   "source": [
    "### Creo el retrieval que devolver√° la informaci√≥n en una busqueda de similitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f407b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval(input_user: str): \n",
    "    vector_store = get_vector_store(\"langchainPrueba\")\n",
    "    docs = vector_store.similarity_search(input_user)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad17eac4",
   "metadata": {},
   "source": [
    "### Creamos el propt system para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b084557",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "    Eres un asistente encargado de responder preguntas sobre Arquitectura de software y solo debes contestar si el contexto no est√° vacio.\n",
    "    En caso de que no cuentes con la informaci√≥n solicitada responde \"La pregunta excede mi conocimiento\" y si te preguntan algo fuera del contexto principal responde \"No estoy programado para eso\".\n",
    "    Utiliza siempre el contexto proporcionado para responder y tambi√©n utiliza un lenguaje familiar y amigable, con carisma.\n",
    "    contexto = {contexto}\n",
    "    pregunta del usuario: {input_user}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf8720a",
   "metadata": {},
   "source": [
    "### Creamos la funci√≥n de respuesta que nos comunicar√° con nuestro agende de IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d64f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(input_user: str, contexto: str):\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "    api_key=api_key,\n",
    "    model=\"gemini-2.0-flash-lite\",\n",
    "    temperature= 0.5\n",
    ")\n",
    "\n",
    "    for chunk in llm.stream(prompt.format(contexto=contexto, input_user=input_user)):\n",
    "        yield chunk.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4180cea",
   "metadata": {},
   "source": [
    "### Utilizamos las funciones para cargar el doc, aplicarle el text_splitter y guardar esos datos como embedding en la base de datos vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d98d533d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={}, page_content='Introducci√≥n  a  RAG   La  generaci√≥n  aumentada  por  recuperaci√≥n  (RAG)  es  el  proceso  de'), Document(metadata={}, page_content='(RAG)  es  el  proceso  de  optimizaci√≥n  de  la  salida'), Document(metadata={}, page_content='de\\n \\nun\\n \\nmodelo\\n \\nde\\n \\nlenguaje\\n \\nde\\n \\ngran\\n \\ntama√±o,\\n \\nde\\n \\nmodo\\n \\nque\\n \\nhaga\\n \\nreferencia\\n \\na'), Document(metadata={}, page_content='que\\n \\nhaga\\n \\nreferencia\\n \\na\\n \\nuna\\n \\nbase\\n \\nde\\n \\nconocimientos\\n \\nautorizada\\n \\nfuera\\n \\nde\\n \\nlos'), Document(metadata={}, page_content='fuera\\n \\nde\\n \\nlos\\n \\nor√≠genes\\n \\nde\\n \\ndatos\\n \\nde\\n \\nentrenamiento\\n \\nantes\\n \\nde\\n \\ngenerar\\n \\nuna'), Document(metadata={}, page_content='antes\\n \\nde\\n \\ngenerar\\n \\nuna\\n \\nrespuesta.\\n \\nLos\\n \\nmodelos\\n \\nde\\n \\nlenguaje\\n \\nde\\n \\ngran\\n \\ntama√±o'), Document(metadata={}, page_content='de\\n \\ngran\\n \\ntama√±o\\n \\n(LLM)\\n \\nse\\n \\nentrenan\\n \\ncon\\n \\nvol√∫menes\\n \\nde\\n \\ndatos\\n \\namplios\\n \\ny\\n \\nusan'), Document(metadata={}, page_content='datos\\n \\namplios\\n \\ny\\n \\nusan\\n \\nmiles\\n \\nde\\n \\nmillones\\n \\nde\\n \\npar√°metros\\n \\npara\\n \\ngenerar\\n \\nresultados'), Document(metadata={}, page_content='para\\n \\ngenerar\\n \\nresultados\\n \\noriginales\\n \\nen\\n \\ntareas\\n \\ncomo\\n \\nresponder\\n \\npreguntas,\\n \\ntraducir'), Document(metadata={}, page_content='preguntas,\\n \\ntraducir\\n \\nidiomas\\n \\ny\\n \\ncompletar\\n \\nfrases.\\n \\nLa\\n \\nRAG\\n \\nextiende\\n \\nlas\\n \\nya'), Document(metadata={}, page_content='RAG\\n \\nextiende\\n \\nlas\\n \\nya\\n \\npoderosas\\n \\ncapacidades\\n \\nde\\n \\nlos\\n \\nLLM\\n \\na\\n \\ndominios\\n \\nespec√≠ficos'), Document(metadata={}, page_content='a\\n \\ndominios\\n \\nespec√≠ficos\\n \\no\\n \\na\\n \\nla\\n \\nbase\\n \\nde\\n \\nconocimientos\\n \\ninterna\\n \\nde\\n \\nuna'), Document(metadata={}, page_content='interna\\n \\nde\\n \\nuna\\n \\norganizaci√≥n,\\n \\ntodo\\n \\nello\\n \\nsin\\n \\nla\\n \\nnecesidad\\n \\nde\\n \\nvolver\\n \\na'), Document(metadata={}, page_content='necesidad\\n \\nde\\n \\nvolver\\n \\na\\n \\nentrenar\\n \\nel\\n \\nmodelo.\\n \\nSe\\n \\ntrata\\n \\nde\\n \\nun\\n \\nm√©todo\\n \\nrentable'), Document(metadata={}, page_content='de\\n \\nun\\n \\nm√©todo\\n \\nrentable\\n \\npara\\n \\nmejorar\\n \\nlos\\n \\nresultados\\n \\nde\\n \\nlos\\n \\nLLM\\n \\nde\\n \\nmodo\\n \\nque'), Document(metadata={}, page_content='los\\n \\nLLM\\n \\nde\\n \\nmodo\\n \\nque\\n \\nsigan\\n \\nsiendo\\n \\nrelevantes,\\n \\nprecisos\\n \\ny\\n \\n√∫tiles\\n \\nen'), Document(metadata={}, page_content='precisos\\n \\ny\\n \\n√∫tiles\\n \\nen\\n \\ndiversos\\n \\ncontextos.'), Document(metadata={}, page_content='¬øCu√°les  son  los  beneficios  de  la  generaci√≥n  aumentada  por  recuperaci√≥n?   La'), Document(metadata={}, page_content='por  recuperaci√≥n?   La  tecnolog√≠a  RAG  aporta  varios  beneficios  a  los  esfuerzos  de  la'), Document(metadata={}, page_content='a  los  esfuerzos  de  la  IA  generativa  de  una'), Document(metadata={}, page_content='organizaci√≥n.'), Document(metadata={}, page_content='‚óè  Implementaci√≥n  rentable:  El  desarrollo  de  chatbots  normalmente  comienza  con  un'), Document(metadata={}, page_content='modelo\\n \\nfundacional.\\n \\nLos\\n \\nmodelos\\n \\nfundacionales\\n \\n(FM)\\n \\nson\\n \\nLLM\\n \\naccesibles\\n \\npara\\n \\nAPI'), Document(metadata={}, page_content='LLM\\n \\naccesibles\\n \\npara\\n \\nAPI\\n \\nentrenados\\n \\nen\\n \\nun\\n \\namplio\\n \\nespectro\\n \\nde\\n \\ndatos'), Document(metadata={}, page_content='espectro\\n \\nde\\n \\ndatos\\n \\ngeneralizados\\n \\ny\\n \\nsin\\n \\netiquetar.\\n \\nLos\\n \\ncostos\\n \\ncomputacionales\\n \\ny'), Document(metadata={}, page_content='costos\\n \\ncomputacionales\\n \\ny\\n \\nfinancieros\\n \\nde\\n \\nvolver\\n \\na\\n \\nentrenar\\n \\na\\n \\nlos\\n \\nFM\\n \\npara'), Document(metadata={}, page_content='a\\n \\nlos\\n \\nFM\\n \\npara\\n \\nobtener\\n \\ninformaci√≥n\\n \\nespec√≠fica\\n \\nde\\n \\nla\\n \\norganizaci√≥n\\n \\no\\n \\ndel'), Document(metadata={}, page_content='la\\n \\norganizaci√≥n\\n \\no\\n \\ndel\\n \\ndominio\\n \\nson\\n \\naltos.\\n \\nLa\\n \\nRAG\\n \\nes\\n \\nun\\n \\nenfoque\\n \\nm√°s'), Document(metadata={}, page_content='es\\n \\nun\\n \\nenfoque\\n \\nm√°s\\n \\nrentable\\n \\npara\\n \\nintroducir\\n \\nnuevos\\n \\ndatos\\n \\nen\\n \\nel\\n \\nLLM.\\n \\nHace'), Document(metadata={}, page_content='en\\n \\nel\\n \\nLLM.\\n \\nHace\\n \\nque\\n \\nla\\n \\ntecnolog√≠a\\n \\nde\\n \\ninteligencia\\n \\nartificial\\n \\ngenerativa\\n \\n(IA'), Document(metadata={}, page_content='artificial\\n \\ngenerativa\\n \\n(IA\\n \\ngenerativa)\\n \\nsea\\n \\nm√°s\\n \\naccesible\\n \\ny\\n \\nutilizable.'), Document(metadata={}, page_content='‚óè  Informaci√≥n  actual:  Incluso  si  los  or√≠genes  de  datos  de  entrenamiento  originales'), Document(metadata={}, page_content='entrenamiento  originales  para'), Document(metadata={}, page_content='un\\n \\nLLM\\n \\nson\\n \\nadecuados\\n \\npara\\n \\nsus\\n \\nnecesidades,\\n \\nes\\n \\ndif√≠cil\\n \\nmantener\\n \\nla\\n \\nrelevancia.'), Document(metadata={}, page_content='mantener\\n \\nla\\n \\nrelevancia.\\n \\nLa\\n \\nRAG\\n \\nles\\n \\npermite\\n \\na\\n \\nlos\\n \\ndesarrolladores\\n \\nproporcionar'), Document(metadata={}, page_content='proporcionar\\n \\nlas\\n \\n√∫ltimas\\n \\ninvestigaciones,\\n \\nestad√≠sticas\\n \\no\\n \\nnoticias\\n \\na\\n \\nlos\\n \\nmodelos'), Document(metadata={}, page_content='noticias\\n \\na\\n \\nlos\\n \\nmodelos\\n \\ngenerativos.\\n \\nPueden\\n \\nusar\\n \\nla\\n \\nRAG\\n \\npara\\n \\nconectar\\n \\nel\\n \\nLLM'), Document(metadata={}, page_content='para\\n \\nconectar\\n \\nel\\n \\nLLM\\n \\nde\\n \\nmanera\\n \\ndirecta\\n \\na\\n \\nredes\\n \\nsociales\\n \\nen\\n \\nvivo,\\n \\nsitios'), Document(metadata={}, page_content='en\\n \\nvivo,\\n \\nsitios\\n \\nde\\n \\nnoticias\\n \\nu\\n \\notras\\n \\nfuentes\\n \\nde\\n \\ninformaci√≥n\\n \\nque\\n \\nse'), Document(metadata={}, page_content='de\\n \\ninformaci√≥n\\n \\nque\\n \\nse\\n \\nactualizan\\n \\ncon\\n \\nfrecuencia.\\n \\nEl\\n \\nLLM\\n \\npuede\\n \\nentonces'), Document(metadata={}, page_content='El\\n \\nLLM\\n \\npuede\\n \\nentonces\\n \\nproporcionar\\n \\nla\\n \\ninformaci√≥n\\n \\nm√°s\\n \\nreciente\\n \\na\\n \\nlos'), Document(metadata={}, page_content='m√°s\\n \\nreciente\\n \\na\\n \\nlos\\n \\nusuarios.'), Document(metadata={}, page_content='‚óè  Mayor  confianza  de  los  usuarios:  La  RAG  le  permite  al  LLM  presentar  informaci√≥n'), Document(metadata={}, page_content='precisa\\n \\ncon\\n \\nla\\n \\natribuci√≥n\\n \\nde\\n \\nla\\n \\nfuente.\\n \\nLa\\n \\nsalida\\n \\npuede\\n \\nincluir\\n \\ncitas\\n \\no'), Document(metadata={}, page_content='puede\\n \\nincluir\\n \\ncitas\\n \\no\\n \\nreferencias\\n \\na\\n \\nfuentes.\\n \\nLos\\n \\nusuarios\\n \\ntambi√©n\\n \\npueden'), Document(metadata={}, page_content='usuarios\\n \\ntambi√©n\\n \\npueden\\n \\nbuscar\\n \\nellos\\n \\nmismos\\n \\nlos\\n \\ndocumentos\\n \\nde\\n \\norigen\\n \\nsi'), Document(metadata={}, page_content='de\\n \\norigen\\n \\nsi\\n \\nnecesitan\\n \\nm√°s\\n \\naclaraciones\\n \\no\\n \\nm√°s\\n \\ndetalles.\\n \\nEsto\\n \\npuede\\n \\naumentar'), Document(metadata={}, page_content='Esto\\n \\npuede\\n \\naumentar\\n \\nla\\n \\nconfianza\\n \\nen\\n \\nsu\\n \\nsoluci√≥n\\n \\nde\\n \\nIA\\n \\ngenerativa.'), Document(metadata={}, page_content='‚óè  M√°s  control  para  los  desarrolladores:  Con  la  RAG,  los  desarrolladores  pueden  \\nprobar'), Document(metadata={}, page_content='probar\\n \\ny\\n \\nmejorar\\n \\nsus\\n \\naplicaciones\\n \\nde\\n \\nchat\\n \\nde\\n \\nmanera\\n \\nm√°s\\n \\neficiente.\\n \\nPueden'), Document(metadata={}, page_content='m√°s\\n \\neficiente.\\n \\nPueden\\n \\ncontrolar\\n \\ny\\n \\ncambiar\\n \\nlas\\n \\nfuentes\\n \\nde\\n \\ninformaci√≥n\\n \\ndel'), Document(metadata={}, page_content='de\\n \\ninformaci√≥n\\n \\ndel\\n \\nLLM\\n \\npara\\n \\nadaptarse\\n \\na\\n \\nlos\\n \\nrequisitos\\n \\ncambiantes\\n \\no\\n \\nal'), Document(metadata={}, page_content='cambiantes\\n \\no\\n \\nal\\n \\nuso\\n \\nmultifuncional.\\n \\nLos\\n \\ndesarrolladores\\n \\ntambi√©n\\n \\npueden'), Document(metadata={}, page_content='tambi√©n\\n \\npueden\\n \\nrestringir\\n \\nla\\n \\nrecuperaci√≥n\\n \\nde\\n \\ninformaci√≥n\\n \\nconfidencial\\n \\na'), Document(metadata={}, page_content='confidencial\\n \\na\\n \\ndiferentes\\n \\nniveles\\n \\nde\\n \\nautorizaci√≥n\\n \\ny\\n \\ngarantizar\\n \\nque\\n \\nel\\n \\nLLM'), Document(metadata={}, page_content='garantizar\\n \\nque\\n \\nel\\n \\nLLM\\n \\ngenere\\n \\nlas\\n \\nrespuestas\\n \\nadecuadas.\\n \\nAdem√°s,\\n \\ntambi√©n\\n \\npueden'), Document(metadata={}, page_content='Adem√°s,\\n \\ntambi√©n\\n \\npueden\\n \\nsolucionar\\n \\nproblemas\\n \\ny\\n \\nhacer\\n \\ncorrecciones\\n \\nsi\\n \\nel\\n \\nLLM'), Document(metadata={}, page_content='si\\n \\nel\\n \\nLLM\\n \\nhace\\n \\nreferencia\\n \\na\\n \\nfuentes\\n \\nde\\n \\ninformaci√≥n\\n \\nincorrectas\\n \\npara'), Document(metadata={}, page_content='incorrectas\\n \\npara\\n \\npreguntas\\n \\nespec√≠ficas.\\n \\nLas\\n \\norganizaciones\\n \\npueden\\n \\nimplementar\\n \\nla'), Document(metadata={}, page_content='pueden\\n \\nimplementar\\n \\nla\\n \\ntecnolog√≠a\\n \\nde\\n \\nIA\\n \\ngenerativa\\n \\ncon\\n \\nmayor\\n \\nconfianza\\n \\npara'), Document(metadata={}, page_content='mayor\\n \\nconfianza\\n \\npara\\n \\nuna\\n \\ngama\\n \\nm√°s\\n \\namplia\\n \\nde\\n \\naplicaciones.'), Document(metadata={}, page_content='Implementaci√≥n  con  Langhain   1.  Cargamos  el  documento  con  PyPDFLoader  y  lo  convertimos'), Document(metadata={}, page_content='y  lo  convertimos  en  un  iterable.  Luego'), Document(metadata={}, page_content='recorremos\\n \\nese\\n \\niterable\\n \\ny\\n \\nguardamos\\n \\ncada\\n \\npage\\n \\nen\\n \\nuna\\n \\nvariable.'), Document(metadata={}, page_content='from langchain_community.document_loaders  import PyPDFLoader  #  cargar  el  documento document'), Document(metadata={}, page_content='el  documento document  =  PyPDFLoader(\"LANGCHAIN.pdf\")   #  creamos  el  iterador loader  ='), Document(metadata={}, page_content='el  iterador loader  =  document.lazy_load()   text  =  \"\" #  recorremos  el  contenido  del'), Document(metadata={}, page_content='el  contenido  del  loader   for page  in loader:       text  +=  page.page_content  2.'), Document(metadata={}, page_content='+=  page.page_content  2.  Importamos  nuestro  separador  de  texto,  lo  implementamos  y'), Document(metadata={}, page_content='texto,  lo  implementamos  y  creamos  los  documentos  que'), Document(metadata={}, page_content='cargaremos\\n \\nposteriormente\\n \\nen\\n \\nnuestra\\n \\nbase\\n \\nde\\n \\ndatos\\n \\nvectorial:'), Document(metadata={}, page_content='from langchain_text_splitters  import CharacterTextSplitter  #  creamos  nuestro  separador  de'), Document(metadata={}, page_content='nuestro  separador  de  texto text_splitter  =  CharacterTextSplitter(      chunk_size=2000,'), Document(metadata={}, page_content='chunk_size=2000,      chunk_overlap=100,      separator=\"\\\\n\" )  #  creamos  los  documentos'), Document(metadata={}, page_content='#  creamos  los  documentos  para  cargar  nuestra  base  de  datos  vectorial texts  ='), Document(metadata={}, page_content='datos  vectorial texts  =  text_splitter.create_documents([text])'), Document(metadata={}, page_content='3.  Importamos  OllamaEmbedding  desde  langchain_ollama  para  utilizar  el  modelo  de'), Document(metadata={}, page_content='embedding'), Document(metadata={}, page_content='from langchain_ollama  import OllamaEmbeddings  #  creamos  la  comunicacion  con  nuestro'), Document(metadata={}, page_content='comunicacion  con  nuestro  modelo  de  embedding embedding  =  OllamaEmbeddings('), Document(metadata={}, page_content='=  OllamaEmbeddings(      model=\"nomic-embed-text\" )     4.  Ahora,  importamos  Chroma  desde'), Document(metadata={}, page_content='importamos  Chroma  desde  langchain_chroma  y  creamos  nuestra  vector  store   from'), Document(metadata={}, page_content='nuestra  vector  store   from langchain_chroma  import Chroma   #  declaramos  la  base  de  datos'), Document(metadata={}, page_content='la  base  de  datos  vectorial vector_store  =  Chroma(      collection_name=\"test\",'), Document(metadata={}, page_content='collection_name=\"test\",      embedding_function=embedding,'), Document(metadata={}, page_content='persist_directory=\"./vectorstore-nomic\" )  5.  Cargamos  los  documentos  que  creamos  en  el'), Document(metadata={}, page_content='que  creamos  en  el  punto  2   #  creamos  los  embeddings  y  lo  guardamos  en  la  base  de'), Document(metadata={}, page_content='guardamos  en  la  base  de  datos  vectorial   vector_store.add_documents(texts)  6.  En  este'), Document(metadata={}, page_content='6.  En  este  punto,  ya  tenemos  documentos  en  nuestra  base  de  datos  vectorial,  por  lo'), Document(metadata={}, page_content='datos  vectorial,  por  lo  tanto,'), Document(metadata={}, page_content='vamos\\n \\na\\n \\ncrear\\n \\nnuestro\\n \\nllm\\n \\nque\\n \\nresponder√°\\n \\npreguntas\\n \\nutilizando\\n \\nla\\n \\ninformaci√≥n'), Document(metadata={}, page_content='la\\n \\ninformaci√≥n\\n \\nque\\n \\nguardamos'), Document(metadata={}, page_content='from langchain_google_genai  import ChatGoogleGenerativeAI  from dotenv  import load_dotenv  import'), Document(metadata={}, page_content='import load_dotenv  import os   load_dotenv()   api_key  =  os.getenv(\"API_KEY\")   llm  ='), Document(metadata={}, page_content='llm  =  ChatGoogleGenerativeAI(      api_key=api_key,      model  =  \"gemini-2.5-flash\",'), Document(metadata={}, page_content='=  \"gemini-2.5-flash\",      temperature=0.5 )  7.  Creamos  un  prompt_template  para  nuestro'), Document(metadata={}, page_content='para  nuestro  llm  con  ChatPromptTemplate   from langchain_core.prompts  import'), Document(metadata={}, page_content='import ChatPromptTemplate  ai_msg  =  [\"\"]  human_msg  =  []   prompt_template  ='), Document(metadata={}, page_content='=  []   prompt_template  =  ChatPromptTemplate.from_messages([      (\"system\",\"\"\"      Eres  un'), Document(metadata={}, page_content='(\"system\",\"\"\"      Eres  un  asistente  encargado  de  responder  preguntas  sobre  Langchain.'), Document(metadata={}, page_content='sobre  Langchain.                     Responde  solo  si   {context}  posee  contenido.  Si  el'), Document(metadata={}, page_content='posee  contenido.  Si  el  contexto  esta  vacio,                      responde  \"No  tengo'), Document(metadata={}, page_content='responde  \"No  tengo  suficiente  informacion  para  reponder  esa  pregunta\"      \"\"\"),'), Document(metadata={}, page_content='esa  pregunta\"      \"\"\"),      (\"ai\",\"{ai_msg}\"),      (\"human\",\"{human_msg}\")  ])'), Document(metadata={}, page_content='8.  Casi  terminamos,  ahora  vamos  a  declarar  una  variable  donde  utilizaremos  un  input,'), Document(metadata={}, page_content='utilizaremos  un  input,  para'), Document(metadata={}, page_content='probar\\n \\nel\\n \\nfuncionamiento\\n \\nde\\n \\nnuestro\\n \\nrag.'), Document(metadata={}, page_content='#  solicitud  del  usuario input_user  =  input(\"Human:  \")  human_msg.append(input_user)  9.  La'), Document(metadata={}, page_content='9.  La  solicitud  del  punto  8,  utilizaremos  para  hacer  una  b√∫squeda  vectorial  con'), Document(metadata={}, page_content='similitary_search.\\n \\nLuego,\\n \\npasaremos\\n \\nun\\n \\ndiccionario\\n \\na\\n \\nnuestro\\n \\nprompt_template\\n \\npara'), Document(metadata={}, page_content='prompt_template\\n \\npara\\n \\nrellenar\\n \\nlas\\n \\nvariables\\n \\nque\\n \\nest√°\\n \\nesperando.'), Document(metadata={}, page_content='docs  =  vector_store.similarity_search(input_user,  k=10)   prompt  =  prompt_template.invoke('), Document(metadata={}, page_content='=  prompt_template.invoke(  {      \"context\":  docs,      \"ai_msg\":  ai_msg,      \"human_msg\":'), Document(metadata={}, page_content='ai_msg,      \"human_msg\":  human_msg  })  10.  Invocamos  el  modelo  con  el  m√©todo  invoke'), Document(metadata={}, page_content='con  el  m√©todo  invoke   response  =  llm.invoke(prompt)   print(response.content)    Resultado'), Document(metadata={}, page_content='Resultado  obtenido:   ‚ï≠‚îÄ  ~\\\\Desktop\\\\langchain  ‚ï∞‚îÄ   Human:  que  son  los  prompt  templates?'), Document(metadata={}, page_content='los  prompt  templates?    AI:  Los  Prompt  Templates  en  Langchain  son  clases  que  permiten'), Document(metadata={}, page_content='son  clases  que  permiten  crear  plantillas  de  mensajes  reutilizables.  Estas  plantillas'), Document(metadata={}, page_content='Estas  plantillas  pueden  definir  variables  (encerradas  entre  llaves  `{}`)  que  se'), Document(metadata={}, page_content='llaves  `{}`)  que  se  llenar√°n  con  valores  espec√≠ficos  al  momento  de  invocar  el  modelo.'), Document(metadata={}, page_content='de  invocar  el  modelo.  Existe  tambi√©n  la  clase  `ChatPromptTemplate`,  que  a  diferencia'), Document(metadata={}, page_content='que  a  diferencia  de  `PromptTemplate`,  espera  un  diccionario  con  las  variables'), Document(metadata={}, page_content='con  las  variables  declaradas  en  el  template.'), Document(metadata={}, page_content='Actividades   Todo  el  contenido  de  la  actividad,  debe  ser  entregado  en  un  j√∫piter'), Document(metadata={}, page_content='entregado  en  un  j√∫piter  notebook,  con  sus'), Document(metadata={}, page_content='correspondientes\\n \\nceldas\\n \\nde\\n \\nmarkdown\\n \\npara\\n \\nla\\n \\ndocumentaci√≥n\\n \\ny\\n \\nceldas\\n \\nde\\n \\nc√≥digo.'), Document(metadata={}, page_content='y\\n \\nceldas\\n \\nde\\n \\nc√≥digo.\\n \\n1.  Implementaci√≥n  Pr√°ctica  de  RAG:'), Document(metadata={}, page_content='‚óè  Recrea  el  ejemplo  dado  en  un  Jupyter  Notebook  o  entorno  de  desarrollo  similar,'), Document(metadata={}, page_content='utilizando\\n \\nlas\\n \\nlibrer√≠as\\n \\nlangchain_community.document_loaders,\\n \\nlangchain_text_splitters,'), Document(metadata={}, page_content='langchain_text_splitters,\\n \\nlangchain_ollama,\\n \\nlangchain_chroma,\\n \\ny\\n \\nlangchain_google_genai.'), Document(metadata={}, page_content='‚óè  Verifica  el  funcionamiento  del  sistema  RAG  respondiendo  a  preguntas  relacionadas  \\ncon'), Document(metadata={}, page_content='con\\n \\nel\\n \\ncontenido\\n \\nde\\n \\nun\\n \\ndocumento\\n \\nX\\n \\n(deben\\n \\nproporcionar\\n \\nuno\\n \\nustedes).'), Document(metadata={}, page_content='uno\\n \\nustedes).\\n \\n2.  Exploraci√≥n  de  Modelos  de  Embedding  y  LLM:'), Document(metadata={}, page_content='‚óè  Experimenta  con  diferentes  modelos  de  embedding  disponibles  en  langchain_ollama'), Document(metadata={}, page_content='(adem√°s\\n \\nde\\n \\n\"nomic-embed-text\")\\n \\ny\\n \\nanaliza\\n \\nc√≥mo\\n \\nimpactan\\n \\nen\\n \\nla\\n \\ncalidad\\n \\nde\\n \\nla'), Document(metadata={}, page_content='en\\n \\nla\\n \\ncalidad\\n \\nde\\n \\nla\\n \\nrecuperaci√≥n\\n \\nde\\n \\ndocumentos.'), Document(metadata={}, page_content='‚óè  Prueba  con  otros  modelos  de  lenguaje  de  gran  tama√±o  (LLM)  compatibles  con'), Document(metadata={}, page_content='langchain_google_genai\\n \\no\\n \\nlangchain_ollama\\n \\ny\\n \\ncompara\\n \\nsus\\n \\nrespuestas\\n \\ny\\n \\nrendimiento.'), Document(metadata={}, page_content='y\\n \\nrendimiento.\\n \\n3.  Optimizaci√≥n  del  Separador  de  Texto:'), Document(metadata={}, page_content='‚óè  Modifica  los  par√°metros  chunk_size  y  chunk_overlap  del  CharacterTextSplitter  y  \\nobserva'), Document(metadata={}, page_content='observa\\n \\nc√≥mo\\n \\nafectan\\n \\na\\n \\nla\\n \\ncreaci√≥n\\n \\nde\\n \\nlos\\n \\ndocumentos\\n \\ny,\\n \\nconsecuentemente,\\n \\na'), Document(metadata={}, page_content='y,\\n \\nconsecuentemente,\\n \\na\\n \\nla\\n \\nprecisi√≥n\\n \\nde\\n \\nlas\\n \\nrespuestas\\n \\ndel\\n \\nLLM.'), Document(metadata={}, page_content='‚óè  Investiga  otros  tipos  de  separadores  de  texto  disponibles  en  Langchain  y  eval√∫a  su'), Document(metadata={}, page_content='en  Langchain  y  eval√∫a  su'), Document(metadata={}, page_content='idoneidad\\n \\npara\\n \\ndiferentes\\n \\ntipos\\n \\nde\\n \\ndocumentos.'), Document(metadata={}, page_content='tipos\\n \\nde\\n \\ndocumentos.\\n \\n4.  Gesti√≥n  de  Bases  de  Datos  Vectoriales:'), Document(metadata={}, page_content='‚óè  Explora  las  funcionalidades  de  Chroma  para  gestionar  colecciones,  persistencia  de'), Document(metadata={}, page_content='datos\\n \\ny\\n \\nrealizar\\n \\nb√∫squedas\\n \\nm√°s\\n \\navanzadas\\n \\n(por\\n \\nejemplo,\\n \\nfiltrado\\n \\nde\\n \\nresultados).'), Document(metadata={}, page_content='‚óè  Investiga  otras  bases  de  datos  vectoriales  compatibles  con  Langchain  y  considera  sus'), Document(metadata={}, page_content='Langchain  y  considera  sus'), Document(metadata={}, page_content='ventajas\\n \\ny\\n \\ndesventajas\\n \\npara\\n \\ndiferentes\\n \\ncasos\\n \\nde\\n \\nuso.'), Document(metadata={}, page_content='casos\\n \\nde\\n \\nuso.\\n \\n5.  Refinamiento  de  Prompts:'), Document(metadata={}, page_content='‚óè  Experimenta  con  diferentes  prompt_template  para  el  LLM,  ajustando  las  instrucciones'), Document(metadata={}, page_content='del\\n \\nsistema\\n \\ny\\n \\nlos\\n \\nmensajes\\n \\nde\\n \\nIA/humano\\n \\npara\\n \\nmejorar\\n \\nla\\n \\ncalidad\\n \\ny'), Document(metadata={}, page_content='mejorar\\n \\nla\\n \\ncalidad\\n \\ny\\n \\nrelevancia\\n \\nde\\n \\nlas\\n \\nrespuestas.'), Document(metadata={}, page_content='‚óè  Implementa  t√©cnicas  de  ingenier√≠a  de  prompts  para  guiar  al  LLM  a  proporcionar'), Document(metadata={}, page_content='respuestas\\n \\nm√°s\\n \\nprecisas\\n \\ny\\n \\n√∫tiles,\\n \\nincluyendo\\n \\nla\\n \\natribuci√≥n\\n \\nde\\n \\nfuentes\\n \\ncuando'), Document(metadata={}, page_content='de\\n \\nfuentes\\n \\ncuando\\n \\nsea\\n \\nposible.')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['420e6f3b-fcae-46f3-81cf-038485919851',\n",
       " '6a7eb5bb-0aa8-4488-8c57-12588256623d',\n",
       " 'b8848432-a3d0-45d6-9087-ae4d1e4b4a87',\n",
       " '4b17398c-9b52-49e0-b4f9-657ab50e9b71',\n",
       " '1e6458c0-1d70-4bc5-8458-0b8664193878',\n",
       " '6ae942d3-50c0-4e62-8dfe-dadcac79c8a0',\n",
       " 'd8ee3049-c2dc-47d8-8f05-ef3dad3b3252',\n",
       " 'e1fad50a-6bcf-4cc3-82cb-451fa7c3efad',\n",
       " '03dc3154-5d09-40e1-8c47-b6086b0375d9',\n",
       " 'b028c627-9969-48de-9053-9450f6ff7b32',\n",
       " '41eca284-6ac9-4346-9f3c-5f80e1bf5231',\n",
       " '6c7e0e1b-939a-4918-ad73-a4424178e453',\n",
       " '8e7df610-5bb0-4782-8edf-5b71809661d0',\n",
       " '1434989b-e169-46ab-9363-47174beea3d8',\n",
       " '03143d11-4df2-4494-a18e-561eb760e98b',\n",
       " '9b412f12-b67a-4c9a-b41e-043d7269d1a7',\n",
       " '76ab9f44-d440-4f57-8fae-a8af1ce3808e',\n",
       " 'aea41400-74a2-4f4b-a63d-c3039559adfd',\n",
       " '608e343f-2e2a-42da-81ec-ff0fcb94c8ae',\n",
       " 'cb79b10a-8994-4f18-85cf-cf45ffbb5beb',\n",
       " 'aca102d3-417d-4875-ad8b-ad147f6bf709',\n",
       " 'a535763d-d6b0-4fd2-b223-249d37d7dc65',\n",
       " 'e58e6eda-1bf0-41b4-b171-8358f2494a54',\n",
       " '49332e1e-8662-45f3-a034-02f488bb3e70',\n",
       " '70dd375b-01de-403c-9a31-635f0e51c5b0',\n",
       " '5a68d25c-cee2-47b8-9602-80c2f131a22a',\n",
       " '94a68a20-4b03-4f71-ab83-f7761b67f7b8',\n",
       " '4e221c17-78ef-4f5d-8801-53210f708345',\n",
       " 'c5f220ce-db5c-4e9d-b1d7-723faf1338d6',\n",
       " '938d1ab3-04ea-4418-b7b3-5d704d46e9a4',\n",
       " 'ebd63763-2860-4de7-a2b2-2e022824c357',\n",
       " '0e7e5953-1950-42b5-83b2-0c5e51a4e43c',\n",
       " 'a6bca68b-7e2a-4663-9740-097e687b1f88',\n",
       " '7b6ec10e-73a7-4737-a5d0-44eb7a11faf1',\n",
       " 'b82a6b5d-a667-489f-bf1c-7536f87a1056',\n",
       " 'bdf95f1d-d39d-4b0a-a308-58bc9f840d98',\n",
       " 'efa96cf5-371f-41a6-8c69-0d0ea67d7d0e',\n",
       " '4919aa63-ae7c-4533-9321-8bf0e340938a',\n",
       " 'd432b916-74f2-4ebd-90de-24ac4b0eeea7',\n",
       " '550d34d3-188b-4690-bf5c-ebbc1c21008d',\n",
       " 'abcad8ec-a719-4803-8687-28ee33dee492',\n",
       " 'c5d4519a-b471-4de4-8084-8c69be1da7a9',\n",
       " '7238ca86-491b-4d7b-b314-d33ece8963f9',\n",
       " 'f74c1ecf-f8d2-4ae2-b823-d843657e4a75',\n",
       " '192ba682-a84a-41ee-b716-13ac7c872a28',\n",
       " 'fd7ceded-6cb7-4bbd-bafb-74ed178a11e5',\n",
       " 'dabb1776-7255-4d9b-9999-532e7e083a64',\n",
       " 'e7c4865b-9308-496e-a16a-89f11c370486',\n",
       " '393db5a8-03dd-4e53-9cc4-d9ba3635f9a0',\n",
       " '14bd66ae-9e7b-4886-801d-f7218499b1a8',\n",
       " '91e17fae-1fc2-4df5-9b8d-a482adad9816',\n",
       " 'b9120439-fc96-469e-ac03-ad53e52f81de',\n",
       " '4d2e1ec7-4522-4b6d-a21a-ff44cdca5754',\n",
       " 'dd894c37-56fc-454e-85f1-a074fc2dffea',\n",
       " '0bf1ed2b-b5ec-48aa-ac20-be1cd3d6a70c',\n",
       " '5899630d-797e-4650-bfa3-6f66bf18060b',\n",
       " '55cdc39f-a8b4-4910-8901-2956884598b4',\n",
       " '11afb5d1-0a18-46b7-95c0-26df36d64166',\n",
       " '49e9c1d5-0ca5-4aa1-811a-b8711746b895',\n",
       " '5d21c3b7-10ba-4503-b0bc-51d2034c6f63',\n",
       " 'a3560f37-a5e3-45dd-87fe-c69aac376d98',\n",
       " 'bb78159c-e495-4325-990f-a56dbeef74f1',\n",
       " 'cced0e58-b280-4127-970c-9aca3ce31d7b',\n",
       " 'c8ee5007-c7a5-442d-af2f-6951b970d443',\n",
       " '68f01a54-67ef-4013-9f7c-6693fab1815d',\n",
       " '7c90ac75-92d5-4ae3-b215-3840674386d2',\n",
       " '89cb96bb-d7aa-464f-b70b-761891154691',\n",
       " 'e8243321-79f4-4e4d-aa9a-7638dc76bc14',\n",
       " 'ce292449-6967-45c1-ba36-90d0e23f8ae1',\n",
       " '301f2b1d-cffa-4cff-915d-85715d1979b6',\n",
       " 'a7ebc7d3-39b3-439f-8ffe-ca37eb91d828',\n",
       " '0249ba59-fd64-4a97-b131-104804bbbdf2',\n",
       " '841dcd7c-b990-46cd-9e15-51168fd99cb0',\n",
       " 'd8def0c2-1cf3-4cef-9214-30a76174f1a6',\n",
       " '073c0fab-d556-4bad-a4d5-93d895657fe3',\n",
       " '3936232f-641e-4818-98d4-2b908fdd97a6',\n",
       " 'b1ba1d22-357b-4f49-ade6-3948b530e9e6',\n",
       " '36ebdf3e-f2d1-44d6-b1d8-5ac529f9a195',\n",
       " 'b1885b0e-36d0-489e-aa10-d4c1af53056d',\n",
       " 'c595fbb9-c3f2-4921-858c-94a0ae271b61',\n",
       " 'a6382ccc-849d-482a-8fc7-34d30aaa68a8',\n",
       " '7e7dfe88-611b-492f-b882-c7776562dd6f',\n",
       " '000b7c3e-6f71-44e6-83c3-7bf0ebd021e6',\n",
       " 'ade2c3ce-09ec-4677-b6e5-065798791aa5',\n",
       " '562ebe9a-5c55-417e-9cad-250ccf1bcc6e',\n",
       " 'd2d68f90-0e22-4c35-a577-58f80d3a914c',\n",
       " '3db7fef1-e138-467c-9287-f588bd86216e',\n",
       " '7c914488-ec77-4e68-add9-8f607f4afdda',\n",
       " 'b51077ea-437f-4828-82b4-11bffcced1f2',\n",
       " '34c8c40b-7ecf-4486-91c6-4de94f73e9ba',\n",
       " 'fb94dc5c-6d4f-4a67-8d06-2ac8fc9da72e',\n",
       " '5c0a95a5-0caf-4a4c-b0d3-29fc9f7f6c8c',\n",
       " '7728dd1d-efc4-474f-981f-c18530bc35b6',\n",
       " 'a0f29bb3-a2aa-4913-b733-e17b76d570b8',\n",
       " '711b7831-21b1-4560-9b12-2f4a2069b9e2',\n",
       " '3fe211aa-8666-476b-8b2e-d7e351cdae53',\n",
       " '7c44de55-bfb8-4245-b2ad-9a3b194ea014',\n",
       " 'a0440c2e-86f7-4e08-b3bf-21c9e47ba13b',\n",
       " 'f966c04b-6ac4-4f99-99b8-22d21853db52',\n",
       " 'c3583a96-08de-43ce-838d-3231edb30dbc',\n",
       " '22d89f7d-5bfd-4f1a-bf2c-ac44bbd8689d',\n",
       " '26638e02-9430-4bee-93b6-d5415afc12a7',\n",
       " '485ba33e-1dfe-446d-9712-a71d601425cb',\n",
       " '3612cef6-244c-49c2-94fe-f407af988809',\n",
       " '715c3352-0470-45c6-b8c8-7414058c8754',\n",
       " '1c20ad5a-e0d6-4e46-89c6-426032674b8b',\n",
       " '30737771-7287-4ad3-9076-ed60a97f5ff4',\n",
       " 'ba9bda5c-8083-4887-99c4-37de90abb9cb',\n",
       " '318941fa-d4cc-471a-a1f9-f68799bfa9da',\n",
       " '4c180941-7e8b-4a2e-9061-d047a043da7d',\n",
       " '465570a7-33b2-462b-a5f1-3f03d7571819',\n",
       " 'e71cc9c3-11fd-4bfc-a219-8e6d01a6ad25',\n",
       " 'ec21e637-e3d1-4ea5-b2d8-3ec48d9338e0',\n",
       " '31213207-89e3-4070-bb8a-02b34d51e39b',\n",
       " '31e15883-3032-4166-b62d-61c69aea3fed',\n",
       " '8ea736c9-cee2-45ec-ba03-10f5ee6d3438',\n",
       " 'af6ae612-286f-4e1b-9e2f-00f240b2fb5f',\n",
       " 'e0f36886-eaae-434b-89ae-d8a5dd04cdb5',\n",
       " 'd6afdf4e-fd17-4bee-9c9c-a02f7fbaeb04',\n",
       " 'af4f0c55-5bb1-4f10-97c0-636dddf9bf68',\n",
       " 'b63b53e0-32db-4195-bd3e-68cc4ec1a989',\n",
       " 'fab634a3-42e2-4c62-87f8-d57e3ff9fc00',\n",
       " 'eacc7adb-b5ea-47d8-9ce1-5e902b2268fe',\n",
       " 'f61f7eee-d82e-4dbd-87d8-7bddcff7d5a5',\n",
       " 'd37cbd72-d73f-415a-be6d-404f58cbf993',\n",
       " '41cb0b64-8137-44bf-8348-01bc5742af99',\n",
       " 'bc35d0fa-61d3-4bf5-a66d-a33f0872cc30',\n",
       " '295d98f9-68d2-475d-88a2-c1b3aca1a954',\n",
       " '3a156c98-d5c0-44f3-9620-f75133a8ca74',\n",
       " '2d60d9ca-4505-40d6-8220-7fd40686b34a',\n",
       " '502e556f-b117-4faa-bded-3a1510002a37',\n",
       " 'aed7f32a-af1f-4bc3-88ce-5233e1399b68',\n",
       " '7468c4e3-02a7-4cfc-9162-3cd180175cb5',\n",
       " 'ea7afa6b-991d-4a87-bb00-a477bca2ce2f',\n",
       " '0d4535fb-53c3-4d01-9e23-de16ebb6380d',\n",
       " '93f32ce6-3640-4393-9bc0-4e1e131f4ffc',\n",
       " 'fff68641-4f97-48b8-b775-b809b40e3888',\n",
       " 'd4282317-96ba-42c0-aed0-0f46def3a794',\n",
       " '010e6550-87e7-4e7b-9b5b-98d955a3e25e',\n",
       " 'e706ba75-8451-47e4-8cc2-f42bc5817a23',\n",
       " 'bd64efbf-1a26-442d-b520-507d4f25c5ea',\n",
       " '83e49181-5b0e-4889-a625-b5c777655280',\n",
       " 'af8638d9-2f63-4285-9f12-08156642b736',\n",
       " '9c5379ad-a6d0-4848-8930-183c6fc38019',\n",
       " '8154535d-adb2-4196-8c92-ea08426da2be',\n",
       " '5e12362a-c546-451d-92ba-95fde3f4dfa5',\n",
       " '27106dde-4e29-45c6-9fad-b35efb68e185',\n",
       " 'c59f990f-6319-43ac-9d0a-1245d613d3f0',\n",
       " '6936a09f-c0c2-403f-9a7a-a14e072858ae',\n",
       " '60cf30e5-419a-4a34-9951-d211c4d05533',\n",
       " 'd2f703aa-38e6-492b-a0ae-75c30b1fe487',\n",
       " '7e5e976d-640f-4bd4-b4e9-d2e5eca33fb6',\n",
       " '192305ac-e28c-4990-a90c-af94c8cc5a47',\n",
       " '65f94ac1-95b7-44e2-9b00-f9a041e46d9f',\n",
       " '4b8a85d7-b5b3-4bce-9b53-0dc11e68e731',\n",
       " '24f24c3d-2c3f-4966-990b-f1da403f9155',\n",
       " 'cf714649-b8af-4746-8594-7cfc18419d59',\n",
       " '1c7cb111-db11-4833-828d-a13bad5c2146']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = upload_pdf(\"asd.pdf\")\n",
    "texts = text_splitter(loader)\n",
    "vector_store = get_vector_store(\"langchainPrueba\")\n",
    "\n",
    "vector_store.add_documents(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df108cc",
   "metadata": {},
   "source": [
    "### Ponemos a prueba nuestro RAG\n",
    "ya que se disminuyo el chunck_size y el overlap nos damos cuenta luego de la primera respuesta ya pierde el contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cecb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola\n",
      "[Document(id='bccb4657-9245-48dd-9d33-94c6faf4fe53', metadata={}, page_content='from langchain_ollama  import OllamaEmbeddings  #  creamos  la  comunicacion  con  nuestro'), Document(id='b1885b0e-36d0-489e-aa10-d4c1af53056d', metadata={}, page_content='from langchain_ollama  import OllamaEmbeddings  #  creamos  la  comunicacion  con  nuestro'), Document(id='073c74da-e3c4-4174-b425-7c98927d9955', metadata={}, page_content='esa  pregunta\"      \"\"\"),      (\"ai\",\"{ai_msg}\"),      (\"human\",\"{human_msg}\")  ])'), Document(id='3612cef6-244c-49c2-94fe-f407af988809', metadata={}, page_content='esa  pregunta\"      \"\"\"),      (\"ai\",\"{ai_msg}\"),      (\"human\",\"{human_msg}\")  ])')]\n",
      "¬°Hola! ¬øEn qu√© puedo ayudarte hoy? üòä\n",
      "que me puedes ense√±ar?\n",
      "[Document(id='72c46248-f623-4561-b054-6d55a10630c5', metadata={}, page_content='en  Langchain  y  eval√∫a  su'), Document(id='9c5379ad-a6d0-4848-8930-183c6fc38019', metadata={}, page_content='en  Langchain  y  eval√∫a  su'), Document(id='191b8de8-1fb1-4e32-bbb2-5498a3a7d49f', metadata={}, page_content='entrenamiento  originales  para'), Document(id='a6bca68b-7e2a-4663-9740-097e687b1f88', metadata={}, page_content='entrenamiento  originales  para')]\n",
      "¬°Hola! Con gusto te puedo ayudar con lo que s√© sobre Langchain y su evaluaci√≥n, bas√°ndome en los documentos de entrenamiento originales. ¬øEn qu√© te puedo ser √∫til?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for l in range(3):\n",
    "    input_user = input(\"Human: \")\n",
    "    print(input_user)\n",
    "\n",
    "    docs = retrieval(input_user=input_user)\n",
    "    print(docs)\n",
    "\n",
    "    for chunk in response(input_user=input_user, contexto=docs):\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8009cfeb",
   "metadata": {},
   "source": [
    "### Al cambiar el chunck_size y el overlap dio una respuesta m√°s concisa, al disminuirlo daba respuestas malas, no tan significativas y comprensibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c2844b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Document(id='08c11b6a-d857-4af3-a582-691a8777a3a8', metadata={}, page_content='a\\n \\nlos\\n \\nFM\\n \\npara\\n \\nobtener\\n \\ninformaci√≥n\\n \\nespec√≠fica\\n \\nde\\n \\nla\\n \\norganizaci√≥n\\n \\no\\n \\ndel'), Document(id='94a68a20-4b03-4f71-ab83-f7761b67f7b8', metadata={}, page_content='a\\n \\nlos\\n \\nFM\\n \\npara\\n \\nobtener\\n \\ninformaci√≥n\\n \\nespec√≠fica\\n \\nde\\n \\nla\\n \\norganizaci√≥n\\n \\no\\n \\ndel'), Document(id='191b8de8-1fb1-4e32-bbb2-5498a3a7d49f', metadata={}, page_content='entrenamiento  originales  para'), Document(id='a6bca68b-7e2a-4663-9740-097e687b1f88', metadata={}, page_content='entrenamiento  originales  para')]\n",
      "¬° Hola! üëã Parece que necesitas ayuda con algo relacionado con Arquitectura de Software. Dime , ¬øen qu√© puedo ayudarte? üòä\n",
      "  hola\n",
      "[Document(id='bccb4657-9245-48dd-9d33-94c6faf4fe53', metadata={}, page_content='from langchain_ollama  import OllamaEmbeddings  #  creamos  la  comunicacion  con  nuestro'), Document(id='b1885b0e-36d0-489e-aa10-d4c1af53056d', metadata={}, page_content='from langchain_ollama  import OllamaEmbeddings  #  creamos  la  comunicacion  con  nuestro'), Document(id='073c74da-e3c4-4174-b425-7c98927d9955', metadata={}, page_content='esa  pregunta\"      \"\"\"),      (\"ai\",\"{ai_msg}\"),      (\"human\",\"{human_msg}\")  ])'), Document(id='3612cef6-244c-49c2-94fe-f407af988809', metadata={}, page_content='esa  pregunta\"      \"\"\"),      (\"ai\",\"{ai_msg}\"),      (\"human\",\"{human_msg}\")  ])')]\n",
      "¬° Hola! üëã Parece que est√°s buscando algo relacionado con Arquitectura de Software. ¬ø En qu√© puedo ayudarte hoy?\n",
      "  "
     ]
    }
   ],
   "source": [
    "\n",
    "for l in range(2):\n",
    "    input_user = input(\"Human: \")\n",
    "    print(input_user)\n",
    "\n",
    "    docs = retrieval(input_user=input_user)\n",
    "    print(docs)\n",
    "\n",
    "    for chunk in response(input_user=input_user, contexto=docs):\n",
    "        print(chunk, end=\" \", flush=True)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
